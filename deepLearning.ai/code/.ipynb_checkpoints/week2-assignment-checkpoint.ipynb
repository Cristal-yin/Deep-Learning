{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1：Python Basics with Numpy (optional assignment)\n",
    "## 1 - Building basic functions with numpy\n",
    "\n",
    "Numpy is the main package for scientific computing in Python. It is maintained by a large community (www.numpy.org). In this exercise you will learn several key numpy functions such as np.exp, np.log, and np.reshape. You will need to know how to use these functions for future assignments.\n",
    "\n",
    "### 1.1 - sigmoid function, np.exp()\n",
    "**Exercise:** Build a function that returns the sigmoid of a real number x. Use math.exp(x) for the exponential function.\n",
    "\n",
    "**Reminder:** \n",
    "sigmoid(x)=11+e−xsigmoid(x)=11+e−x is sometimes also known as the logistic function. It is a non-linear function used not only in Machine Learning (Logistic Regression), but also in Deep Learning.\n",
    "\n",
    "![13](../images/13.png)\n",
    "\n",
    "To refer to a function belonging to a specific package you could call it using package_name.function(). Run the code below to see an example with math.exp()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: basic_sigmoid\n",
    "\n",
    "import math\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute sigmoid of x.\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    s = 1.0/(1 + 1/math.exp(x))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525741268224334"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_sigmoid(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we rarely use the “math” library in deep learning because the inputs of the functions are real numbers. In deep learning we mostly use matrices and vectors. This is why numpy is more useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8ccefa5bf989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### One reason why we use \"numpy\" instead of \"math\" in Deep Learning ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbasic_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# you will see this give an error when you run it, because x is a vector.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-4fa960d22fc2>\u001b[0m in \u001b[0;36mbasic_sigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m### START CODE HERE ### (≈ 1 line of code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not list"
     ]
    }
   ],
   "source": [
    "### One reason why we use \"numpy\" instead of \"math\" in Deep Learning ###\n",
    "x = [1, 2, 3]\n",
    "basic_sigmoid(x) # you will see this give an error when you run it, because x is a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, if x=(x1,x2,...,xn)x=(x1,x2,...,xn) is a row vector then np.exp(x)np.exp(x) will apply the exponential function to every element of x. The output will thus be: np.exp(x)=(ex1,ex2,...,exn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.71828183  7.3890561  20.08553692]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# example of np.exp\n",
    "x = np.array([1, 2, 3])\n",
    "print(np.exp(x)) # result is (exp(1), exp(2), exp(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, if x is a vector, then a Python operation such as s=x+3s=x+3 or s=1xs=1x will output s as a vector of the same size as x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# example of vector operation\n",
    "x = np.array([1, 2, 3])\n",
    "print (x + 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Implement the sigmoid function using numpy.\n",
    "\n",
    "Instructions: x could now be either a real number, a vector, or a matrix. The data structures we use in numpy to represent these shapes (vectors, matrices…) are called numpy arrays. You don’t need to know more for now. \n",
    "\n",
    "For \n",
    "$x \\in \\mathbb{R}^n sigmoid(x) = sigmoid\\begin{pmatrix} x_1  \\\\\n",
    "    x_2  \\\\\n",
    "    ...  \\\\\n",
    "    x_n  \\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\\frac{1}{1+e^{-x_1}}  \\\\\n",
    "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
    "    ...  \\\\\n",
    "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
    "\\end{pmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "import numpy as np # this means you can access numpy functions by writing np.function() instead of numpy.function()\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of x\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array of any size\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    s = 1.0 / (1 + 1 / np.exp(x))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.95257413])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2,3])\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Sigmoid gradient\n",
    "**Exercise:** Implement the function sigmoid_grad() to compute the gradient of the sigmoid function with respect to its input x. The formula is:\n",
    "\n",
    "$sigmoid_derivative(x)=σ′(x)=σ(x)(1−σ(x))$\n",
    "\n",
    "You often code this function in two steps: \n",
    "1. Set s to be the sigmoid of x. You might find your sigmoid(x) function useful. \n",
    "2. Compute σ′(x)=s(1−s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid_derivative\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    Compute the gradient (also called the slope or derivative) of the sigmoid function with respect to its input x.\n",
    "    You can store the output of the sigmoid function into variables and then use it to calculate the gradient.\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array\n",
    "\n",
    "    Return:\n",
    "    ds -- Your computed gradient.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    s = 1.0 / (1 + 1 / np.exp(x))\n",
    "    ds = s * (1 - s)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid_derivative(x)= [0.19661193 0.10499359 0.04517666]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3])\n",
    "print('sigmoid_derivative(x)= '+ str(sigmoid_derivative(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Reshaping arrays\n",
    "Two common numpy functions used in deep learning are np.shape and np.reshape(). \n",
    "- X.shape is used to get the shape (dimension) of a matrix/vector X. \n",
    "- X.reshape(…) is used to reshape X into some other dimension.\n",
    "\n",
    "For example, in computer science, an image is represented by a 3D array of shape $(length,height,depth=3)$. However, when you read an image as the input of an algorithm you convert it to a vector of shape $(length∗height∗3,1)$. In other words, you “unroll”, or reshape, the 3D array into a 1D vector.\n",
    "![14](../images/14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Implement image2vector() that takes an input of shape (length, height, 3) and returns a vector of shape (length*height*3, 1). For example, if you would like to reshape an array v of shape (a, b, c) into a vector of shape (a*b,c) you would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-94b48c862a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'v' is not defined"
     ]
    }
   ],
   "source": [
    "v = v.reshape((v.shape[0]*v.shape[1],v.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: image2vector\n",
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    image -- a numpy array of shape (length, height, depth)\n",
    "\n",
    "    Returns:\n",
    "    v -- a vector of shape (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    v = image.reshape((image.shape[0] * image.shape[1] * image.shape[2], 1))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image2vector(image) = [[0.67826139]\n",
      " [0.29380381]\n",
      " [0.90714982]\n",
      " [0.52835647]\n",
      " [0.4215251 ]\n",
      " [0.45017551]\n",
      " [0.92814219]\n",
      " [0.96677647]\n",
      " [0.85304703]\n",
      " [0.52351845]\n",
      " [0.19981397]\n",
      " [0.27417313]\n",
      " [0.60659855]\n",
      " [0.00533165]\n",
      " [0.10820313]\n",
      " [0.49978937]\n",
      " [0.34144279]\n",
      " [0.94630077]]\n"
     ]
    }
   ],
   "source": [
    "# This is a 3 by 3 by 2 array, typically images will be (num_px_x, num_px_y,3) where 3 represents the RGB values\n",
    "image = np.array([[[ 0.67826139,  0.29380381],\n",
    "        [ 0.90714982,  0.52835647],\n",
    "        [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85304703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.60659855,  0.00533165],\n",
    "        [ 0.10820313,  0.49978937],\n",
    "        [ 0.34144279,  0.94630077]]])\n",
    "\n",
    "print (\"image2vector(image) = \" + str(image2vector(image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - Normalizing rows\n",
    "Another common technique we use in Machine Learning and Deep Learning is to normalize our data. It often leads to a better performance because gradient descent converges faster after normalization. Here, by normalization we mean changing x to x‖x‖x‖x‖ (dividing each row vector of x by its norm).\n",
    "\n",
    "For example, if\n",
    "$x = \n",
    "\\begin{bmatrix}\n",
    "    0 & 3 & 4 \\\\\n",
    "    2 & 6 & 4 \\\\\n",
    "\\end{bmatrix}\\tag{3}$\n",
    "then\n",
    "$\\| x\\| = np.linalg.norm(x, axis = 1, keepdims = True) = \\begin{bmatrix}\n",
    "    5 \\\\\n",
    "    \\sqrt{56} \\\\\n",
    "\\end{bmatrix}\\tag{4}$\n",
    "and\n",
    "$x\\_normalized = \\frac{x}{\\| x\\|} = \\begin{bmatrix}\n",
    "    0 & \\frac{3}{5} & \\frac{4}{5} \\\\\n",
    "    \\frac{2}{\\sqrt{56}} & \\frac{6}{\\sqrt{56}} & \\frac{4}{\\sqrt{56}} \\\\\n",
    "\\end{bmatrix}\\tag{5}$\n",
    "Note that you can divide matrices of different sizes and it works fine: this is called broadcasting and you’re going to learn about it in part 5.\n",
    "\n",
    "\n",
    "**Exercise:** Implement normalizeRows() to normalize the rows of a matrix. After applying this function to an input matrix x, each row of x should be a vector of unit length (meaning length 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: normalizeRows\n",
    "\n",
    "def normalizeRows(x):\n",
    "    \"\"\"\n",
    "    Implement a function that normalizes each row of the matrix x (to have unit length).\n",
    "\n",
    "    Argument:\n",
    "    x -- A numpy matrix of shape (n, m)\n",
    "\n",
    "    Returns:\n",
    "    x -- The normalized (by row) numpy matrix. You are allowed to modify x.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    # Compute x_norm as the norm 2 of x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)\n",
    "    x_norm = np.linalg.norm(x, axis=1, keepdims = True)  #计算每一行的长度，得到一个列向量\n",
    "\n",
    "    # Divide x by its norm.\n",
    "    x = x / x_norm  #利用numpy的广播，用矩阵与列向量相除。\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizeRows(x)=[[0.         0.6        0.8       ]\n",
      " [0.13736056 0.82416338 0.54944226]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [0, 3, 4],\n",
    "    [1,6,4]\n",
    "])\n",
    "print('normalizeRows(x)=' + str(normalizeRows(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "In normalizeRows(), you can try to print the shapes of x_norm and x, and then rerun the assessment. You’ll find out that they have different shapes. This is normal given that x_norm takes the norm of each row of x. So x_norm has the same number of rows but only 1 column. So how did it work when you divided x by x_norm? This is called broadcasting and we’ll talk about it now!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 - Broadcasting and the softmax function\n",
    "A very important concept to understand in numpy is “broadcasting”. It is very useful for performing mathematical operations between arrays of different shapes. For the full details on broadcasting, you can read the official broadcasting documentation.\n",
    "\n",
    "**Exercise:** Implement a softmax function using numpy. You can think of softmax as a normalizing function used when your algorithm needs to classify two or more classes. You will learn more about softmax in the second course of this specialization.\n",
    "\n",
    "Instructions: \n",
    "$\\text{for } x \\in \\mathbb{R}^{1\\times n} \\text{,     } softmax(x) = softmax(\\begin{bmatrix}  \n",
    "    x_1  &&  \n",
    "    x_2 &&  \n",
    "    …  &&  \n",
    "    x_n  \n",
    "\\end{bmatrix}) = \\begin{bmatrix}\n",
    "     \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n",
    "    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n",
    "    ...  &&\n",
    "    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}} \n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\text{for a matrix } x \\in \\mathbb{R}^{m \\times n} \\text{,  $x_{ij}$ maps to the element in the $i^{th}$ row and $j^{th}$ column of $x$, thus we have: } \\\\softmax(x) = softmax\\begin{bmatrix}\n",
    "    x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
    "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
    "\\end{bmatrix} \\\\= \\begin{pmatrix}\n",
    "    softmax\\text{(first row of x)}  \\\\\n",
    "    softmax\\text{(second row of x)} \\\\\n",
    "    ...  \\\\\n",
    "    softmax\\text{(last row of x)} \\\\\n",
    "\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax\n",
    "\n",
    "def softmax(x):\n",
    "    x_exp = np.exp(x)\n",
    "    x_sum = np.sum(x_exp, axis = 1, keepdims = True) \n",
    "    s = x_exp / x_sum\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax(x) = [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
      "  1.21052389e-04]\n",
      " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
      "  8.01252314e-04]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [9,2,5,0,0],\n",
    "    [7,5,0,0,0]\n",
    "])\n",
    "print('softmax(x) = '+ str(softmax(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### note:\n",
    "需要记住的是：\n",
    "+ np.exp(x)\n",
    "+ the sigmoid 函数和它的梯度函数\n",
    "+ image2vector 通常使用在深度学习中\n",
    "+ np.reshape 被广泛的应用\n",
    "+ numpy在创建函数上有很高的效率\n",
    "+ 广播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量化\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot=278\n",
      "----Computation time = 0.15400000000020952ms\n",
      "outer=[[81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [63. 14. 14. 63.  0. 63. 14. 35.  0.  0. 63. 14. 35.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "----Computation time = 0.38400000000038403ms\n",
      "mul=[81.  4. 10.  0.  0. 63. 10.  0.  0.  0. 81.  4. 25.  0.  0.]\n",
      "----Computation time = 0.188000000000077ms\n",
      "gdot=[20.92691161 21.69211408 25.71818309]\n",
      "----Computation time = 0.28199999999989345ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "tic = time.process_time()\n",
    "dot = 0\n",
    "for i in range(len(x1)):\n",
    "    dot += x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print('dot='+str(dot)+'\\n----Computation time = '+ str(1000*(toc-tic)) + 'ms')\n",
    "\n",
    "\n",
    "\n",
    "#  \n",
    "tic = time.process_time()\n",
    "outer = np.zeros((len(x1),len(x2)))   # 初始化一个乘出来的矩阵\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        outer[i,j] = x1[i]*x2[j]\n",
    "toc = time.process_time()\n",
    "print('outer='+str(outer)+'\\n----Computation time = '+ str(1000*(toc-tic)) + 'ms')\n",
    "\n",
    "\n",
    "tic = time.process_time()\n",
    "mul = np.zeros(len(x1))\n",
    "for i in range(len(x1)):\n",
    "    mul[i] = x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print('mul='+str(mul)+'\\n----Computation time = '+ str(1000*(toc-tic)) + 'ms')\n",
    "\n",
    "\n",
    "\n",
    "W = np.random.rand(3, len(x1))    #  随机化 3 * len(x1)大小的numpy矩阵\n",
    "tic = time.process_time()\n",
    "gdot = np.zeros(W.shape[0])\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(len(x1)):\n",
    "        gdot[i] += W[i,j]*x1[j]\n",
    "toc = time.process_time()\n",
    "print('gdot='+str(gdot)+'\\n----Computation time = '+ str(1000*(toc-tic)) + 'ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot= 278\n",
      "……Computation time=0.140000000000029ms\n",
      "outer=[[81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [63 14 14 63  0 63 14 35  0  0 63 14 35  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "……Computation time=0.15399999999976544ms\n",
      "elementwise multuplucation=[81  4 10  0  0 63 10  0  0  0 81  4 25  0  0]\n",
      "……Computation time=0.10999999999983245ms\n",
      "gdot=[20.92691161 21.69211408 25.71818309]\n",
      "……Computation time=0.11599999999978294ms\n"
     ]
    }
   ],
   "source": [
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "tic = time.process_time()\n",
    "dot = np.dot(x1, x2)\n",
    "toc = time.process_time()\n",
    "print('dot= '+ str(dot) + '\\n……Computation time='+str(1000*(toc - tic)) + 'ms')\n",
    "\n",
    "\n",
    "\n",
    "tic = time.process_time()\n",
    "outer = np.outer(x1, x2)\n",
    "toc = time.process_time()\n",
    "print('outer='+str(outer) + '\\n……Computation time='+str(1000*(toc - tic))+ 'ms')\n",
    "\n",
    "\n",
    "tic = time.process_time()\n",
    "mul = np.multiply(x1, x2)\n",
    "toc = time.process_time()\n",
    "print('elementwise multuplucation='+str(mul) + '\\n……Computation time='+str(1000*(toc - tic))+'ms')\n",
    "\n",
    "\n",
    "\n",
    "tic = time.process_time()\n",
    "dot = np.dot(W, x1)\n",
    "toc = time.process_time()\n",
    "print('gdot='+str(dot) + '\\n……Computation time='+str(1000*(toc- tic))+'ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1(yhat, y):\n",
    "    loss = np.sum(np.abs(y - yhat))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1=1.1\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9,0.2,0.1,.4,.9])\n",
    "y = np.array([1,0,0,1,1])\n",
    "print('L1='+str(L1(yhat,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(yhat, y):\n",
    "    loss = np.sum(np.power((y-yhat),2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 = 0.43\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4,.9])\n",
    "y = np.array([1,0,0,1,1])\n",
    "print('L2 = '+ str(L2(yhat, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要记住的是：\n",
    "+ 向量化\n",
    "+ L1 L2范数\n",
    "+ numpy函数  np.sum   np.abs  np.dot  np.multiply  np.maximum etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2： Logistic Regression with a Neural Network mindset\n",
    "You will learn to: \n",
    "- Build the general architecture of a learning algorithm, including: \n",
    "- Initializing parameters \n",
    "- Calculating the cost function and its gradient \n",
    "- Using an optimization algorithm (gradient descent) \n",
    "- Gather all three functions above into a main model function, in the right order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from lr_utils import load_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据集：**\n",
    "+ m_train 训练集\n",
    "+ m_test 测试集\n",
    "+ the shape of each image (num_px,num_px,3)  3 channels(RGB)\n",
    "    height = num_px   weight = num_px\n",
    "\n",
    "\n",
    "'-orig'代表预处理   每一个train_set_x_orig都代表一个图像数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [1],it's a cat  picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 24\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print('y = '\n",
    "      + str(train_set_y[:, index]) \n",
    "      + ',it\\'s a ' \n",
    "      + classes[np.squeeze(train_set_y[:, index])].decode('utf-8')\n",
    "      + '  picture.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "练习\n",
    "\n",
    "其中\n",
    "train_set_x_orig 是一个numpy-array shape is （m_shape,num_px, num_px,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 209\n",
      "Number of testing examples: m_test = 50\n",
      "Height/Width of each image: num_px = 64\n",
      "Each image is of size: (64, 64, 3)\n",
      "train_set_x shape: (209, 64, 64, 3)\n",
      "train_set_y shape: (1, 209)\n",
      "test_set_x shape: (50, 64, 64, 3)\n",
      "test_set_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "\n",
    "print('Number of training examples: m_train = '+ str(m_train))\n",
    "print('Number of testing examples: m_test = '+ str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.ones(27)\n",
    "X = X.reshape((3,3,3))\n",
    "X.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_flatten = X.reshape(X.shape[0],-1).T\n",
    "X_flatten.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了方便， 我们可以reshape图像 (num_px,num_px,3)   to  (num_px*num_px*3,1)\n",
    "因此   数据集的列所代表的就是一个  展开的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (12288, 209)\n",
      "train_set_y shape: (1, 209)\n",
      "test_set_x_flatten shape: (12288, 50)\n",
      "test_set_y shape: (1, 50)\n",
      "sanity check after reshaping: [17 31 56 22 33]\n"
     ]
    }
   ],
   "source": [
    "train_set_x_flatten = train_set_x_orig.reshape(m_train,-1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(m_test, -1).T\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288, 209)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_x_flatten.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255\n",
    "test_set_x = test_set_x_flatten/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**需要记住**\n",
    "+ 维度   和  表示图像数据的shape\n",
    "+ reshape数据集\n",
    "+ 标准化数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归实际上是一个非常简单的神经网络\n",
    "![15](../images/15.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1.0/(1 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0, 2]) = [0.5        0.88079708]\n"
     ]
    }
   ],
   "source": [
    "print('sigmoid([0, 2]) = ' + str(sigmoid(np.array([0, 2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   初始化参数\n",
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0\n",
    "    \n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.]\n",
      " [0.]]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print('w = '+ str(w))\n",
    "print('b = '+ str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  前向传播\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    cost = -(1.0/m)*np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))\n",
    "    \n",
    "    dw = (1.0/m)*np.dot(X,(A-Y).T)\n",
    "    db = (1.0/m)*np.sum(A - Y)\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    # squeeze()函数将表示向量的数组转换为秩为1的数组,这样利用matplotlib库函数画图时,就可以正常的显示结果了。\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\":dw,\n",
    "            \"db\":db}\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw = [[0.99845601]\n",
      " [2.39507239]]\n",
      "db = 0.001455578136784208\n",
      "cost = 5.801545319394553\n"
     ]
    }
   ],
   "source": [
    "w, b, X, Y = np.array([[1.],[2.]]), 2.,np.array([[1.,2.,-1.],[3.,4.,-3.2]]),np.array([[1,0,1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print('Cost after iteration %i:%f' % (i,cost))\n",
    "            \n",
    "    params = {\"w\":w,\n",
    "              \"b\":b}\n",
    "    grads = {\"dw\":dw,\n",
    "              \"db\":db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.19033591]\n",
      " [0.12259159]]\n",
      "b = 1.9253598300845747\n",
      "dw = [[0.67752042]\n",
      " [1.41625495]]\n",
      "db = 0.21919450454067657\n"
     ]
    }
   ],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations = 100, learning_rate = 0.009, print_cost = False)\n",
    "\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w =  w.reshape(X.shape[0], 1)\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0,i] > 0.5:\n",
    "            Y_prediction[0,i] = 1\n",
    "            \n",
    "        else:\n",
    "            Y_prediction[0,i] = 0\n",
    "            \n",
    "    assert(Y_prediction.shape == (1,m))\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[0.1124579],[0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note:**\n",
    "+ 初始化(w, b)\n",
    "+ 优化损失函数更新（w,b）\n",
    "+ 计算损失函数和梯度\n",
    "+ 更新参数\n",
    "+ 用学习到的(w, b) 预测样本"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gluon] *",
   "language": "python",
   "name": "conda-env-gluon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
