[TOC]

## 第四周学习笔记

### week03 超参数调试、Batch正则化和程序框架(Hyperparameter tuning)

#### 3.1 调试处理

神经网络的改变涉及到了很多的超参数设置。

训练深度最难的事情之一就是要处理的参数的数量，从学习速率$\alpha$ 到 **Momentum** (动量梯度下降法)的参数$\beta$ 。

如果使用 **Momentum** 或 **Adam** 优化算法的参数，$\beta_1,\beta_2$ 和 $$\varepsilon$$ ,也许你还得选择层数，等等。

最广泛的学习应用是 $\alpha$ ，学习速率是需要调试的最重要的超参数。

**如果尝试调节一些超参数，该如何选择调试值？** 

+ ![](images/0401.png) 

  对于两个超参数，常用的做法是在网络中取样点，然后逐一尝试所有的点，看哪个参数效果最好。(适用于参数少的时候)

+ 常用的方法：**随机选择点** 用随机选取的点试验超参数的效果。

  假如有三个超参数，则搜索的范围就变成了一个立方体

+ 由粗到细

  ![](images/0402.png)

  现在大区域中找到合适的点，再缩小范围。

#### 3.2 为超参数选择合适的范围(Using an appropiate scale to pick hyperparameters)

随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺，用于探究这些超参数。

```r = -4*np.random.rand()```  可以得出$r \in [-4, 0]$然后$\alpha$ 随机取值，$\alpha = 10^r$ ,那么$\alpha \in [10^{-4}, 10^0]$ 

**$\Large {\color{red}{总结}}$** 在对数坐标下取值，取最小值的对数就得到 $\alpha$ 的值，取最大值的对数就得到$b$ 值。

给$\color{maroon}{\beta}$ 取值,用于计算指数的加权平均值。如果想在$\mathrm{0.9}$ 到 $0.999$ 区间搜索，就不能用线性轴取值。因此我们选择探究 $1-\beta$ ，此值在$0.1$到$0.001$ 之间。 即 $10^{-1}$ , $10^{-3}$ 。

当$\beta$ 接近于 $1$ 时， 所得结果的灵敏度会变化，即使 $\beta$ 有微小的变化。因此在$\beta$ 即将接近于 1 的时候  要更加紧密的取值，才能更加有效地分布取样点，更有效率的探究可能的结果。

#### 3.3 超参数调试实践：Pandas VS Caviar(Hyperparameters tuning in practice: Pandas VS. Caviar)

搜索超参数的问题两种重要的思想

![](images/0403.png)

+ 第一种是照看一个模型，拥有庞大的数据组，但没有许多计算资源或足够的 $CPU$ 和 $GPU$ 的前提下。一次负担起试验一个模型或一个小批模型，在这样的情况下，即使当它在试验时， 也可以逐渐改良。
+ 第二种方法就是同时试验多种模型，设置一些超参数，尽管让它自己运行。

#### 3.4 归一化网络的激活函数

+ **Batch归一化**

  **Batch** 归一化会使你的参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会使你的训练更加容易，甚至是深层网络。

  归一化输入特征可以加快学习过程。这是如何把学习问题的轮廓，从很长的东西，变成更圆的东西，更易于算法优化。

  在实践中，经常做的归一化 是 $z^{[2]}$ 

  ![](images/0404.png)

  把这些 z值标准化，化为含平均值0 和标准单位方差，所以z的每一个分量都含有平均值0和方差1，但是我们不想让隐藏单元总是含有平均值0和方差1，也许隐藏单元有了不同的分布会有意义，所以我们要计算$\check{z}^{(i)}$ 

  $\check{z}^{(i)} = \gamma z_{norm}^{(i)} + \beta$  其中 $\gamma \ , \beta$ 都是要学习的参数，所以我们使用梯度下降或一些其他类似梯度下降的算法，比如 **Momentum**或者 **Nesterov, Adam**来更新$\gamma \ \beta$ 

  **$\large{\color{red}{\gamma \ 和 \beta 的作用：}}$ ** 可以随意设置 $\check{z}^{(i)}$ 的平均值 ，事实上 ，如果 $\gamma = \sqrt{\sigma^2 + \varepsilon}$ 

  $\beta = \mu$ 那么$ \gamma z_{norm}^{(i)} + \beta$ 的作用就在于，它会精确转化这个方程 $\check{z}^{(i)} = z^{(i)}$ 

   通过赋予$\gamma \ \beta$ 其他的值，可以构造含有其他平均值和方差的隐藏单元值。

  均值和方差可以使 0 和 1， 也可以是其他值，由$\gamma$ 和 $\beta$ 来决定。

#### 3.5 将Batch Norm 拟合进神经网络(Fitthing Batch Norm into a neural network)

![](images/0405.png)

每个单元负责两件事：计算z，然后应用到激活函数中再计算 a。

Batch归一化的做法是将 $z^{[1]}$ 值进行Batch归一化，简称 **BN** ,此过程将由 $\beta^{[1]}$ 和 $\gamma^{[1]}$ 两参数控制，这一操作会给你一个新的规范化的 $z^{[1]}$ 值($\check{z}^{[1]}$) ，然后将其输入到激活函数中得到 $a^{[1]}$ 即 $a^{[1]} = g^{[1]}(\check{z}^{[l]})$ 

在实践中，**Batch**归一化通常和训练集的 **mini-batch**一起使用。

![](images/0406.png)

在计算过程中 $z^{[l]}  = w^{[l]}a^{[l-1]} + b^{[l]}$ 。但 **Batch** 归一化做的是，它要看这个 **mini-batch**，先将 $z^{[l]}$ 归一化，结果为均值0和标准房差，再由$\beta $ 和 $\gamma$ 重缩放。但这意味着，无论 $b^{[l]}$ 的值是多少，都是要被减去的，因为在 **Batch**归一化的过程中，你要计算 $z^{[l]}$ 的均值，再减去平均值，在此例中的 **mini-batch**中添加任何常数，数值都不会改变。所以在使用 **Batch**归一化，可以消除这个参数 $b^{[l]}$ ，或者设置为0，

![](images/0407.png)

各个参数的维数。更新各个参数：

$w^{[l]} = w^{[l]} - \alpha dw^{[l]} \\ \beta^{[l]} = \beta^{[l]} - \alpha d\beta^{[l]} \\ \gamma^{[l]} = \gamma^{[l]} - \alpha d\gamma^{[l]}$

这也适用于 **Monentum、RMSprop、Adam** 的梯度下降法。

也可以使用其他的一些优化算法来更新由 **Batch**归一化添加到算法中的 $\beta$ 和 $\gamma$ 参数。

#### 3.6 Batch Norm 为什么奏效？(Why does Batch Norm work?)

通过归一化所有的输入特征值 $x$ ， 以获得类似范围的值，可以加速学习。

它可以使权重比你的网络更滞后或更深层。

**Covariate shift** 如果你已经学习了 x 到 y  的映射，如果 x 的分布改变了，那么你可能需要重新训练你的学习算法。

**Covariate shift** 的问题怎么应用于神经网络呢？

![](images/0408.png)

例如此神经网络，从第三隐藏层开始学起，他得到一些值，如图，但这些值也可能是特征值 $x_1, x_2, x_3,x_4$，第三隐藏层的工作是找到一种方式，使这些值映射到 $\hat{y}$ 。

隐藏层的值在不断改变， **Batch**归一化做的，是它减少了这些隐藏值分布变化的数量。**Batch**归一化讲的是 $z_1^{[2]} ，z_2^{[2]}$ 的值可以改变，他们的确会改变，当神经网络在之前层中更新参数，**Batch**归一化可以确保无论其怎么变化 $z_1^{[1]} ， z_2^{[2]}$ 的均值和方差保持不变，所以即使 $z_1^{[1]} ， z_2^{[2]}$ 的值改变，至少他们的均值和方差也会是均值0， 方差1，或不一定必须是均值0，方差1，而是由 $\beta^{[2]} , \gamma^{[2]}$ 决定的值。

**Batch**归一化减少了输入值改变的问题，它的确使这些值变得更稳定，神经网络的之后层就会有更坚实的基础。即使时输入分布改变小一些，它的改变会更小。它做的是当前层保持学习，当改变时，迫使后层适应的程度减小了，它减弱了前层参数的作用与后层参数的作用之间的联系。它使得网络每层都可以自己学习，稍稍独立于其它层，这有助于加速整个网络的学习。

**Batch**归一化还有一个作用，它有轻微的正则化效果，**Batch**归一化中非直观的一件事是，每个 **mini-batch**上计算的均值和方差，而不是在整个数据集上，均值和方差有一些小的噪声，因为它只在你的 **mini-batch**上计算，比如64或128或256或更大的训练例子。

在此过程中会有一些噪音。所以和 **dropout** 相似，它往每个隐藏层的激活层上增加了噪音， **dropout**有增加噪音的方式，它使一个隐藏的单元，以一定的概率乘以0，以一定的概率乘以1，所以你的dropout含几重噪音，因为它乘以0或1。

应用较大的 **mini-batch**可以减少正则化效果。

不要把 **Batch**归一化当做正则化，把它当做将你归一化隐藏单元激活值并加速学习的方法。

#### 测试时的 Batch Norm(Batch Norm at test time)

**Batch** 归一化将你的数据以 **mini-batch**的形式逐一处理，但在测试时，你可能需要对每个样本逐一处理。

![](images/0410.png)

​	用于调节计算的 $\mu$ 和 $\sigma^2$ 是在整个 **mini-batch**上进行计算，但是在测试时，可能不能将一个 **mini-batch**中的6428或2056个样本同时处理，因此你需要用其他方式来得到 $\mu$ 和 $\sigma^2$ ，而且如果你只有一个样本，一个样本的均值和方差没有意义。实际上，为了将你的神经网络运用与测试，就需要单独估算 $\mu$ 和 $\sigma^2$ ，在典型的 **Batch**归一化运用中，你需要用一个指数加权平均来估算，这个平均数涵盖了所有 **mini-batch**

![](images/0411.png)

在训练时， $\mu$ 和 $\sigma^2$ 是在整个 **mini-batch**上计算出来的包含了像是64或28或其他一定数量的样本，但在测试时，你可能需要逐一处理样本，方法是根据你的训练集估算 $\mu$ 和 $\sigma^2$ ，估算的方式有很多种， 理论上你可以在最终的网络中运行整个训练集来得到 $\mu$ 和 $\sigma^2$ ，但在实际操作中，我们通常运用指数加权平均来追踪在训练过程中你看到的 $\mu$ 和 $\sigma^2$ 的值。然后在测试中使用 $\mu$ 和 $\sigma^2$ 的值来进行你所需要的隐藏单元z值得调整。

​	使用 **Batch**归一化，你能够训练更深的网络，让你的学习算法运行速度更快。

#### 3.8 Softmax 回归 (Softmax regression)

多分类方式：逻辑回归。

![](images/0412.png)

输出层有4个，输出层单元的数字告诉我们这4中类型中每个概率有多大，所以这里的第一个节点输出的应该是或者说我们希望它输出"其他"类的概率。

这里的$\hat{y}$ 是一个$4 \times 1$ 的向量，因为它必须输出四个数字。给定四个概率，且概率相加等于1。

让网络做到这一点的标准模型要用到 **Softmax层** ，以及输出层来生成输出。

和往常一样计算  $z^{[l]} = W^{[l]}a^{[L-1]} + b^{[l]}$ ，算出了 z之后，需要应用 **Softmax**激活函数，这个激活函数对于 **Softmax** 层而言有些不同。

**它的作用是这样的：**

首先计算一个临时变量  $\large t = e^{z^{[l]}}$  , 这是对所有元素求幂， t也是一个 $4 \times 1$ 维向量，然后输出的 $a^{[l]}$ ,基本上就是向量 t ，但是会归一化，使其和为1。因此 $\large{a^{[l]} = \frac{e^{z^{[l]}}}{\sum_{i=1}^4t_i}}$ 

#### 3.9 训练一个Softmax分类器

Softmax回归或Softmax激活函数将logistic激活函数推广到 C 类，而不仅仅是两类。结果如果是 C = 2，那么 C = 2 的 **Softmax**实际上变回了 **logistic**回归

**Sotfmax**回归将 **logistic** 回归推广到了两种分类以上。

+ **用什么样的损失函数来训练这个神经网络？** 

  在 **Softmax**中我们一般用到的损失函数是$L(\hat{y}, y) = -\sum_{j=1}^4y_ilog\hat{y}_j$ 

损失函数所做的就是找到训练集中的真实类别，然后试图使该类别相应的概率尽可能地高。

整个训练样本的损失值：$J(w^{[1]}, b^{[1]},……) = \frac{1}{m}\sum_{i = 1}^mL(\hat{y}^{(i)},y^{(i)})$

这里要用梯度下降法，使损失最小化。

#### 3.11 TensorFlow

损失函数： $Jw = w^2 - 10w + 25$ 

**$\large{\color{maroon}{TensorFlow实现损失函数最小化}}$**

**placeholder**函数会告诉 **TensorFlow** 它稍后会为 x 提供数值。

```cost = x[0][0]*w**2 + x[1][0]*w + x[2][0]```

**TensorFlow**程序的核心是计算损失函数，然后 **TensorFlow**自动计算出导数，以及如何最小化损失，因此这行代码或者这个等式所做的就是让 **TensorFlow**建立计算图，计算图所做的就是取 $x[0][0]$ ，取 w ，然后将它平方，然后 $x[0][0]$ 和 $w^2$ 相乘，以此类推，最后得到损失函数。

**TensorFlow**的优点在于，通过用这个计算损失，计算图基本实现前向传播，**TensorFlow**已经内置了所有必要的反向函数

### 03week01 机器学习策略

#### 1.1 为什么是ML策略

对于一个猫狗分类，我们可能有很多想法。

+ 收集更多的数据
+ 收集更多类别的训练集
+ 训练梯度下降算法
+ 换一种梯度下降算法，例如Adam
+ 尝试更大的网络
+ 尝试更小的网络
+ 尝试dropout
+ 添加$L_2$正则化
+ 网络结构
  + 激活函数
  + 隐藏单元

但是如何更好的选择正确的方向。

#### 1.2 正交化(Orthogonalization)

对于机器学习系统的挑战之一，就是需要尝试和改变的东西很多。

专家就是能够对症下药

对于要调整什么来达到某个效果，非常清楚，这个步骤称之为正交化。

**正交化的概念**可以相处一个维度，这个维度你想做的就是控制转向角，还有另一个维度来控制你的速度，那么你就需要一个旋钮尽量只控制你的转向角和速度，同时改变两个性质，那么就很难令你的车子以想要的速度和角度前进。然而正交化之后，正交意味着互成90度，设计出正交化的控制装置，最理想的情况是和你实际想控制的性质一致，这样你调整参数时就容易得多，可以单独调整转向角，还有你的油门和刹车，令车子以你想要的方式运动。

调节系统，需要确保四件事：

+ 训练集上的表现必须通过某种评估
+ 希望在开发集上有好的表现
+ 在测试集上有好的表现
+ 在实际应用中有好的表现

在训练神经网络时， 尽量不用 **early stopping**,早期停止有点难以分析，因为这个旋钮会同时影响你对训练集的拟合，如果使用 **early  stopping**,那么对训练集的拟合就不太好，但它同时也用来改善开发集的表现，所以这个旋钮没那么正交化。因为他同事影响两件事情。

#### 1.3 单一数字评估指标

有一个单实数评估指标，进展会很快。

应用机器学习是一个非常经验性的过程，通常有一个想法：编程序、跑试验、看效果，然后使用这些实验结果来改善你的想法。

**查准率**的定义是在你的分类器标记为猫的例子中，有多少真的是猫

**查全率**就是，对于所有真猫的图片，你的分类器正确识别出了多少百分比。实际为猫的图片中，有多少被系统识别出来？

事实上，查准率和查全率之间往往需要折中，两个指标都要顾忌到。

但是如果有两个评估指标就很难快速选出好的那一个。

查全率的标准方法是所谓的 $F_1$ 分数，$\large{ F_1 = \frac{2}{\frac{1}{P} +\frac{1}{R}}}$

在数学中这个函数叫做查准率 $P$ 和查全率 $R$ 的调和平均数。

#### 1.4 满足和优化目标

通过定义优化和满足指标，就可以给你提供一个明确的方式，去选择"最好的"分类器。

如果选择 $N$ 个指标，有时候选择其中一个指标作为优化指标是合理的。

如果你需要顾及多个指标，比如说，有一个优化指标，你想尽可能优化的，然后还有一个或多个满足指标，需要满足的，需要达到一定的门槛。现在你就有一个全自动的方法，在观察多个成本大小时，选出"最好的"那个。现在这些评估指标必须是在训练集或开发机或测试集上计算或求出来的。所以你还需要做一件事情，就是设立训练集、开发集、还有测试集。

#### 1.5 训练/开发/测试集划分

如何划分这些数据集，才能让开发效率变快呢？

开发集(development set)，有时称为保留交叉验证集(hold out cross validation set)

开发集和测试集最好来自同一分布。

设立你的开发集加上一个单实数评估指标，这就是像是定下目标，然后告诉你的团队，那就是你要瞄准的靶心，因为你一旦建立了这样的开发集和指标，团队就可能快速迭代，尝试不同的想法，跑试验，可以很快地使用开发集和指标去评估不同分类器，然后尝试选出最好的那个。

将所有的数据随机洗牌，放入开发集和测试集，因此开发集和测试集就来自同一分布。

#### 1.6 开发集和测试集的大小

对于较小的数据集划分：$70\%、30\% $ 或 $60\%、 20\%、20\%$ 

规模大得多的数据集:$98\%、1\%、1\%$ 

测试集的目的是完成系统开发之后，测试集可以帮你评估投产系统的性能。

对于某些应用，你也许不需要对系统性能有置信度很高的评估，也许你只需要训练集和开发集。那么不单独分出一个测试集也是可以的。

事实上，还有要有 **测试集** 的。

#### 1.7 什么时候该改变开发/测试集合指标？

**分类错误率指标**：

$\large {Error = \frac{1}{m_{dev}} \sum_{i = 1}^{m_{dev}}{I\{y_{pred}^{(i)} \ne y^{(i)}\}} }$

$m_{dev}$ 是你的开发集例子数，$y_{pred}^{(i)}$ 表示预测值，其值为0 或1 ，$I$ 表示一个函数，统计出里面这个表达式为真的样本数，所以这个公式就统计了分类错误的样本。

对修改评估指标加权重：

$\large {Error = \frac{1}{m_{dev}} \sum_{i = 1}^{m_{dev}}{w^{(i)}I\{y_{pred}^{(i)} \ne y^{(i)}\}} }$

用来筛选一些特殊信息，例如、色情图片，赋予这些信息的权重极大值。

错误率归一化：

$\large {Error = \frac{1}{\sum w^{(i)}} \sum_{i = 1}^{m_{dev}}{w^{(i)}II\{y_{pred}^{(i)} \ne y^{(i)}\}} }$

如果你的评估指标无法正确评估好算法的排名，那么就需要花时间定义一个新的评估指标。这是定义评估指标的其中一种可能方式(加权法)。评估指标的意义在于，准确告诉你一致两个分类器，哪一个更适合你的应用。这实际上是一个正交化的例子。

在处理机器学习问题时， 应该把它切分成独立的步骤。

+ 弄清楚如何定义一个指标来衡量你想做的事情的表现
+ 然后我们可以分开考虑如何改善系统在这个指标上的表现。

如何定义损失函数不重要，关键在于正交化的思路，把设立目标定为第一步，然后瞄准和射击目标是独立的第二步。

#### 1.8 为什么是人的表现？

如何比较机器学习系统和人类的表现？

深度学习系统的进步，机器学习算法突然变得更好了，在许多机器学习的应用领域已经开始见到算法已经可以威胁到人类的表现了。事实证明，当你试图让机器做人类能做的事情时， 可以静心设计机器学习系统的工作流程，让工作流程效率更高，所以在这些场合，比较人类和机器是很自然的，或者你要让机器模仿人类的行为。

**贝叶斯最优错误率（Bayesian）** 认为是理论上可能达到的最优错误率，就是说没有任何办法设计出一个 $x$ 到 $y$ 的函数，让它能够超过一定的准确度。

#### 1.9 可避免偏差

人类能做到的水平和贝叶斯错误率相差不远。

把贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为可避免偏差。

训练错误率和开发错误率之间的差值，就大概说明你的算法在方差问题上还有多少改善的空间。

当你理解人类水平错误率，理解你对贝叶斯错误率的估计，你就可以在不同的场景中专注于不同的策略，使用避免偏差策略还是避免方差策略，在训练时如何考虑人类水平表现来决定工作着力点。

#### 1.10 理解人的表现

"人类水平错误率"就是理论最低的错误率，任何函数不管是现在还是未来，能够到达的最低值。

在定义人类水平错误率时， 要弄清楚你的目标所在，如果要表明你可以超越单个人类，那么就有理由在某些场合部署你的系统。

只有了解了人类水平错误率 训练错误率和测试错误率的关系才能判断式需要调整方差还是偏差。

如果你想理解偏差和方差，那么在人类可以做到很好的任务中，你可以估计人类水平的错误率，你可以使用人类水平错误率来估计贝叶斯错误率。所以你到贝叶斯错误率估计值得差距，告诉你可避免偏差问题有多大，可避免偏差问题有多严重，而训练错误率和开发错误率之间的差值告诉你方差上的问题有多大，你的算法是否能够从训练集泛化推广到开发集。

对人类水平有大概的估计可以让你做出对贝叶斯错误率的估计，这样可以让你更快地做出决定是否应该专注于减少算法的偏差，或者减少算法的方差。这个决策几千通常很有效，直到你的系统性能开始超越人类，那么你对贝叶斯错误率的估计就不再准确了，但这些技巧还是可以帮你做出明确的决定。